\section{Network Management} \label{chap:nm} 

\par The topic of network management is very extensive, due to the several components that make up today's networks, and the vast amount of information that they
provide. It can be summed up as the operation and maintenance of network infrastructure so that the service it provides is not only "healthy", but also is operated
at a level that keeps costs down for service providers. 

\subsection {Requirements for management systems}

\par As the complexity of the networks, and network devices that compose them, grows bigger and bigger, the management systems should accommodate for the their
necessities. As such, the basic groups of requirements for management functions  defined in the ITU-T X 700 Recommendation \cite{noauthor_recommendation_1992}
are:

\begin {itemize}
    \item \textbf {Fault management} is the capability for detection, isolation and correction of abnormal operation in the system
    \item \textbf {Accounting management} provides ways to monitor the system resource utilization, and using this data to generate information about the costs that
        the operation of a certain resource will incur. This allows for optimizing the network utilization of resources, as it provides insights on how to
        plan the evolution of the network
    \item \textbf {Configuration management} is related to the maintenance and updates of hardware and software in the network, and the general setup of devices 
        that allow to start, maintain and terminate services 
    \item \textbf {Performance management} relates to monitor systems for the traffic utilization, response time, performance and logging histories. This allows to 
        maintain Service Level Agreements (SLA) between the service provider and the client, providing better services even in cases of unusual traffic.
    \item \textbf {Security management} enables setting up security policies in terms of access control to resources, private information protection, among others.
\end {itemize}

\par A network management system usually consists of a centralized station, and management agents running on the network devices. Using management protocols, the
agents can report to the station information about the its operational status, which includes information ranging from CPU load to bandwidth usage. Typically this
information can be retrieved by the controller polling the agents, or the agents sending information on their own, usually to inform status changes. Using this 
information, the network operator can get insight on the performance or possible errors of the devices that are monitored. In the next section, we explore one of the
most popular management protocols, SNMP.

\subsection {SNMP}

The Simple Network Management Protocol is an IETF defined protocol that allows for the interconnection of networking devices, and provide a structured way to
retrieve relevant information about these devices. As the name suggests, SNMP allows for a simplified approach to network monitoring, since it reduces the complexity
of the functions that the management agent needs to comply with, which bring several advantages, like reducing the costs for development of management tools;
provides a way to monitor, independently from different hardware providers the resources; and also supports freedom in extending the protocol in order to include
other aspects of network operation \cite{fedor_simple_1990}.
\par The architectural model of SNMP can be described in figure \ref{fig:snmp}.
    
\begin{figure} [!htbp]
    \centering
    \includegraphics[width=.6\textwidth]{nm/snmp_arch}
    \caption{Architectural components of SNMP}
    \label{fig:snmp}
\end{figure}

The management database is one of the most important components of this system, because it serves as a reference to the entities that are managed in the SNMP
protocol. The formal name for this database is the MIB - Management Information Base \cite{rose_structure_1990}, and its composed of a collection of objects.

\par Each object has a name, syntax and encoding \cite{rose_management_1990}. The name of the object, more specifically, the \textit {Object Identifier (OID)}, is a
reference to the object itself. This name is usually a list of integers, and they serve to build a tree-like hierarchy. This structure allows for the organization 
of all objects in a logical pattern, as there is a parent node that contains references to their children, which provides different indexes for different objects. 
For human readability, there is usually an \textit {Object Descriptor}, to refer to the object type. 

\par The syntax defines the type of data structure in the object type; and the encoding describes how the object type is transmitted on the network. In the context
of this thesis, an important group is the interfaces group, as this exposes information about the interfaces present in a system. Its OID is the .3.6.1.2.1.2., 
and contains the number of interfaces in a system, and a table containing the counters related to the interface status, like the received unicast packets, the 
physical address, among others. The flexibility of the MIB allows for vendors to introduce their own databases into the MIB, while also remaining compatible 
with the standardized one.

\par Due to its permanence in the market, the protocol has suffered some large changes since its original design. SNMPv3 now supports important changes to the
original one, most notably in the security aspects, introducing strong authentication and encryption capabilities.

\subsection {Data Center Networks (DCN)}

\par The design of the network architecture is central to the data-center networks, as the placement for physical hosts and virtual machines allows for sharing the 
resources and create a logical hierarchy of network devices. The study on the design of DCN has resulted in the creation of typical DC topologies, like fat-tree
topologies (as seen in \ref{fig:fattree}), or others, including de Bruijn server only networks, or BCube switch heavy networks \cite{popa_cost_2010}. This approach
allows for the traffic characteristics, resource consumption and costs of the networking devices be monitored, so that causes for failure of this network are
understood and mitigated, and the entire DC can run on the most optimal way possible. The organization in the DCN also allows for traffic in the network being
resistant to failure scenarios, since there are multiple paths that can redirect packets to the correct destination, even if a link to a switch fails.

\begin{figure} [!htbp]
    \centering
    \includegraphics[width=1\textwidth]{nm/fattree}
    \caption{Visual representation of the fat tree topology commonly used in data centers}
    \label{fig:fattree}
\end{figure}

\subsubsection {DCN and SDN}

\par The centralized view that SDN controllers maintain over the networks allows for it to keep the information about the flows currently present in the network. As
such, the SDN paradigm allows for flexible control of the path the packets take in the network, and improves performance of the network at a large
scale. By joining the information available on DCN and SDN, the requirements for traffic engineering (TE) in SDN, from the perspective of flow control are flow 
management, fault tolerance and traffic analysis \cite{akyildiz_research_2016}. This set of four requirements set the base for properly monitoring a DCN from the 
perspective of the SDN paradigm.
\par The next section are taken from \cite{akyildiz_research_2016}.

\subsubsection {Flow management}

Flow management refers to the capability that the controller has to set rules for packet forwarding, and maintain the low overhead that is associated with
registering a new flow rule, and also limiting the amount of flow entries, as hardware switches usually have a set amount of flow entries that they can support.

\par If we consider the fat-tree topology, one obvious consequence is the fact that if one controller is responsible for the management of the entire underlying 
topology, a bottleneck can be created when the rules need to be deployed to a node. When the switch receives a new packet, and there 
are no rules to properly forward this packet, then the packet is redirected to the controller, on the form of a \textsc{PACKET\_IN} message, and after processing
this packet, a new flow rule is sent to the switch. The problem with this scenario lies in the delay that it takes between the reception of the packet, and the
installation of the new flow entry, which can be a contributing factor in packet losses in the data plane. This is an attack vector that is also explored in
Distributed Denial of Service (DDoS) attacks for SDN platforms, as in an extreme scenario, the spoofed packet addresses will not have matches on the tables, which
then result on overflowing the controller \cite{mousavi_early_2015}.

\par A solution for this issue is then related to decreasing the number of messages sent to the controller, by introducing some load balancing concepts. One of
these concepts is related to the way that we can install the flow entries on the switch. The information present in the packets serve to generate the flow-match
entries that are deployed on the table. To reduce the number of interactions between the controller and OF switches, then we can reduce the number of match fields
present in the flow rules, which reduces the number of flow entries on the switch and the controller messages. Another solution is distributing the controller among
the network, but keeping them connected via a separate channel.

\subsubsection {Fault tolerance} \label{sec:fault_tolerance}

Although the switches are connected in a way that are able to mitigate link or other switch failures, in the case of faults occurring there needs to be the
possibility of creation of new forwarding rules. An even bigger concern lies in the case when the controller fails, which will pose a larger problem in the network. 
For the case of node failure, fast recovery means that the OF controller can reactively act on link failures, by signaling the switches to forward packets toward 
new locations; or proactively, by setting the rules prior to the occurrence of the failure. In the case that the failure is short lived, then the controller is also 
responsible of resetting the paths to the optimal state. The way that controllers handle their connection is independent of the OpenFlow connection, and the
failover should occur with minimal changes to the underlying flow rules and overhead.

\subsubsection {Traffic analysis}

So that the management tools can correctly display information about the state of the network, status statistics should be continuously collected and analysed. These
statistics should provide the information about flows, packets and ports, so that the measured metrics can serve as a baseline for the decisions of the controller to
adapt the flow rules to enable the best possible performance. The statistics collection can be collected in two possible ways: by continuously sampling
packets from the switches; or applying sampling techniques, and generalizing the information from the sampled data \cite{curtis_mahout:_2011}. The problem here lies
in the collection of the statistics in poses a problem for large scale deployments, where continuously polling the network devices introduces both overhead and very 
large amounts of data to be parsed, or the data is not enough to detect failures in a short amount of time. 

\subsection {Statistics}

\subsubsection {OpenFlow}

After exploring the requirements for network management, and the way the SDN model can support developing better systems, we now focus on the possibilities for
obtaining this information from the networking devices. The OpenFlow protocol maintains a set of counters for each flow entry, port and group statistics, and this
information can be queried to obtain a general view on the status of each OF switch. By sending specific controller-to-switch messages, the switch will return a set
of the maintained statistics, which can then be parsed and analysed further. 

\par Sending the port statistics message returns an array with the measured counters for each port. These counters include information like the amount of received
and transmitted bytes/ packets, errors and dropped packets, and the duration that the port is alive. 

\par The next important message is the \textsc{OFMP\_FLOW} message, since this allows for getting the individual flow statistics, and obtain the information about
each flow entry, including the time that it has been set on the switch, the number of packets/bytes in the flow, and the match fields. Also worth noting are the 
aggregate flow messages which describe how many packets are in the total flow entries, and also the number of flow entries that exist.

\par Also relevant is the information that is retrieved using the group statistics, as they allow to monitor the number of flows that direct to the group, and again
the packet/ byte count that are matched with this group.

\par The information provided from these messages allows for a comprehensive view of the state of each switch, and a Network Management System (NMS) can utilize
this information to achieve an understanding of the state of the network. 

\subsubsection {sFlow} \label{sec:sflow}

One problem arises, however, when periodic requests generate too much information, and the control channel is overflowed with messages of port statistics, which is
a possible scenario when the flow tables start getting too large. As such, a different alternative is to sample a small amount of packets from the switch, send the
packet headers to the controller. One approach to this method is \textit{sFlow}, a standard for collection, analysis and storage of network flows and traffic, for 
each device and its interfaces. sFlow is implemented using embedded agents on switches and routers, which compile interface and flow samples and exports them to the 
sFlow collector via datagrams. 

\par Due to the problems that arise with continuously collecting traffic data, packet sampling has emerged as a valid solution to this problem, by collecting every
\textit{n}-th packet. The simplicity of the technique allows for reducing the complexity of sFlow agents, and having the sampling operation being done in 
hardware, resulting in the collection of the samples being done at the same speed of the channel it is monitoring. This reduces the losses that are inherent to the
sampling process, which leads to biased analysis of the traffic \cite{brauckhoff_impact_2006}.

\begin{figure} [!htbp]
    \centering
    \includegraphics[width=.6\textwidth]{nm/sflow_diagram}
    \caption{Architectural components of sFlow}
    \label{fig:sflow}
\end{figure}

\par Figure \ref{fig:sflow} shows the basic architecture that composes the sFlow system. One advantage of this system is the number of systems that incorporate sFlow
agents \footnote {Complete list of compliant devices: http://www.sflow.org/products/network.php}, allowing for a detailed analysis of flows, and enabling flexibility
for scalability in the network. By utilizing a sFlow collector that can accurately collect and process the datagrams incoming from the Agents, this protocol can be
used to control most of the central aspects in network management, like troubleshooting network problems; controlling congestion on the network; or even analysing
the possible security threats internal and external to the network.
